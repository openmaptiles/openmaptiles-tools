#!/usr/bin/env python
"""
Import names from the Wikidata Query Service

Usage:
  import-wikidata <tileset> [--storage=<table>]
                  [--pghost=<host>] [--pgport=<port>] [--dbname=<db>]
                  [--user=<user>] [--password=<password>]
                  [--verbose]
  import-wikidata --table=<table>... [--storage=<table>]
                  [--pghost=<host>] [--pgport=<port>] [--dbname=<db>]
                  [--user=<user>] [--password=<password>]
                  [--verbose]
  import-wikidata --help
  import-wikidata --version

  <tileset>             Tileset definition yaml file

Options:
  -t --table=<table>    Process specific table(s) rather than auto-detecting it from tileset.
  -w --storage=<table>  Write results to this table.  [default: wd_names]
  -v --verbose          Print additional debugging information
  --help                Show this screen.
  --version             Show version.

PostgreSQL Options:
  -h --pghost=<host>    Postgres hostname. By default uses POSTGRES_HOST env or "localhost" if not set.
  -P --pgport=<port>    Postgres port. By default uses POSTGRES_PORT env or "5432" if not set.
  -d --dbname=<db>      Postgres db name. By default uses POSTGRES_DB env or "openmaptiles" if not set.
  -U --user=<user>      Postgres user. By default uses POSTGRES_USER env or "openmaptiles" if not set.
  --password=<password> Postgres password. By default uses POSTGRES_PASSWORD env or "openmaptiles" if not set.
"""

import asyncio
from collections import defaultdict

import asyncpg
from asyncpg import Connection
from docopt import docopt
from typing import Iterable, List

import requests
import openmaptiles
from openmaptiles.pgutils import parse_pg_args, PgWarnings
from openmaptiles.tileset import Tileset
from openmaptiles.utils import batches


async def main(args):
    verbose = args['--verbose']
    storage_table = args['--storage']
    tileset_path = args['<tileset>']
    tables = find_tables(tileset_path) if tileset_path else args['--table']

    pghost, pgport, dbname, user, password = parse_pg_args(args)
    conn = await asyncpg.connect(
        database=dbname, host=pghost, port=pgport, user=user, password=password,
    )
    PgWarnings(conn)
    await conn.set_builtin_type_codec('hstore', codec_name='pg_contrib.hstore')

    print(f'Searching for Wikidata IDs in {len(tables)} tables...')
    ids = await find_needed_wd_ids(conn, tables, verbose)
    print(f'Found {len(ids):,} Wikidata IDs to load.')
    print(f'Deleting any existing data in {storage_table}...')
    await conn.execute(f'TRUNCATE TABLE {storage_table}')
    print(f'Inserting Wikidata IDs...')
    for batch in batches(ids, 5000, lambda v: f'wd:Q{v}'):
        records = defaultdict(dict)
        query = f'''\
SELECT ?id ?label WHERE {{
  VALUES ?id {{ {' '.join(batch)} }}
  ?id rdfs:label ?label.
}}'''
        if verbose:
            print(f"----------\n{query}\n----------")
        for row in wd_query(query):
            lang = 'name:' + row['label']['xml:lang']
            records[entity_id(row['id'])][lang] = row['label']['value']
        await conn.copy_records_to_table(
            storage_table, columns=['id', 'labels'], records=records.items())
    print(f'Finished inserting {len(ids):,} Wikidata IDs.')


def find_tables(tileset_path, table_prefix='osm_'):
    """Find all tables in the imposm mapping files that may contain Wikidata IDs"""
    tileset = Tileset.parse(tileset_path)
    tables = set()
    for layer in tileset.layers:
        for mapping in layer.imposm_mappings:
            for table_name, table_def in mapping['tables'].items():
                if 'fields' not in table_def or (
                    '_resolve_wikidata' in table_def and
                    not table_def['_resolve_wikidata']
                ):
                    continue
                fields = table_def['fields']
                if any((v for v in fields
                        if v['name'] == 'tags' and v['type'] == 'hstore_tags')):
                    tables.add(table_prefix + table_name)
    tables = list(sorted(tables))
    print(f"Found {len(tables)} tables with the 'tags' hstore fields")
    for table in tables:
        print(f"  * {table}")
    return tables


async def find_needed_wd_ids(conn: Connection, tables: Iterable[str],
                             verbose: bool) -> List[int]:
    ids = []
    part = [f"SELECT tags->'wikidata' AS id FROM {t} WHERE tags ? 'wikidata'"
            for t in tables]
    query = f"""\
SELECT DISTINCT id
FROM (({') UNION ('.join(part)})) as t
WHERE id SIMILAR TO 'Q[1-9][0-9]{{0,18}}'"""
    if verbose:
        print(f"----------\n{query}\n----------")
    for row in await conn.fetch(query):
        ids.append(int(row['id'][1:]))
    ids.sort()
    return ids


def entity_id(column):
    return column['value'][len('http://www.wikidata.org/entity/'):]


def wd_query(sparql):
    r = requests.post(
        'https://query.wikidata.org/bigdata/namespace/wdq/sparql',
        data={'query': sparql},
        headers={
            'Accept': 'application/sparql-results+json',
            'User-Agent': f'OpenMapTiles OSM name resolver {openmaptiles.__version__}'
                          '(https://github.com/openmaptiles/openmaptiles)'
        })
    try:
        if not r.ok:
            print(r.reason)
            print(sparql)
            raise Exception(r.reason)
        return r.json()['results']['bindings']
    finally:
        r.close()


if __name__ == '__main__':
    asyncio.run(main(docopt(__doc__, version=openmaptiles.__version__)))
