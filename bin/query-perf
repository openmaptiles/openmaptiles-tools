#!/usr/bin/env python
"""
Refresh all PostgreSQL materialized views in parallel, taking into account cross-dependencies.

Usage:
  query-perf <tileset> [--test=<set>]... [--layer=<layer>]...
             ([--zoom=<zoom>]... | [--minzoom=<min>] [--maxzoom=<max>])
              [--buckets=<count>] [--verbose]

  query-perf --help
  query-perf --version

  <tileset>             Tileset definition yaml file

Options:
  -t --test=<set>       Which predefined test to run.  [default: us-across]
  -l --layer=<layers>   Limit testing to a specific layer (could be more than one)
  -z --zoom=<zoom>      Limit testing to a specific zoom. If set, ignores min/max.
  -m --minzoom=<min>    Test tiles in zooms more or equal to this value  [default: 14]
  -n --maxzoom=<max>    Test tiles in zooms less or equal to this value  [default: 14]
  -b --buckets=<count>  Show up to this many buckets in a graph  [default: 10]
  -v --verbose          Print additional debugging information.
  --help                Show this screen.
  --version             Show version.

PostgreSQL Connection Options:
  -h --pghost=<host>    Postgres hostname. By default uses PGHOST env or "localhost" if not set.
  -P --pgport=<port>    Postgres port. By default uses PGPORT env or "5432" if not set.
  -d --dbname=<db>      Postgres db name. By default uses PGDATABASE env or "openmaptiles" if not set.
  -U --user=<user>      Postgres user. By default uses PGUSER env or "openmaptiles" if not set.
  --password=<password> Postgres password. By default uses PGPASSWORD env or "openmaptiles" if not set.

Postgres
  These legacy environment variables should not be used, but they are still supported:
     POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD
"""
import asyncio
import os.path
import shutil
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta
from functools import reduce
from math import ceil
from typing import List, Tuple, Dict

import asyncpg
from ascii_graph import Pyasciigraph
from asyncpg import Connection, UndefinedFunctionError, UndefinedObjectError
from docopt import docopt, DocoptExit

import openmaptiles
from openmaptiles.sqltomvt import MvtGenerator
from openmaptiles.utils import coalesce, round_td


def main(args):
    zooms = [int(v) for v in args['--zoom']]
    if not zooms:
        zooms = list(range(int(args['--minzoom']), int(args['--maxzoom']) + 1))

    asyncio.run(async_main(
        tileset=args['<tileset>'],
        test=args['--test'],
        layers=args['--layer'],
        buckets=int(args['--buckets']),
        zooms=zooms,
        pghost=coalesce(
            args.get("--pghost"), os.getenv('POSTGRES_HOST'), os.getenv('PGHOST'),
            'localhost'),
        pgport=coalesce(
            args.get("--pgport"), os.getenv('POSTGRES_PORT'), os.getenv('PGPORT'),
            '5432'),
        dbname=coalesce(
            args.get("--dbname"), os.getenv('POSTGRES_DB'), os.getenv('PGDATABASE'),
            'openmaptiles'),
        user=coalesce(
            args.get("--user"), os.getenv('POSTGRES_USER'), os.getenv('PGUSER'),
            'openmaptiles'),
        password=coalesce(
            args.get("--password"), os.getenv('POSTGRES_PASSWORD'),
            os.getenv('PGPASSWORD'), 'openmaptiles'),
        verbose=args.get('--verbose'),
    ))


@dataclass
class TestCase:
    id: str
    desc: str
    start: Tuple[int, int]  # inclusive tile coordinate (x,y)
    before: Tuple[int, int]  # exclusive tile coordinate (x,y)
    zoom: int = 14
    duration: timedelta = None

    def __post_init__(self):
        assert self.id and self.desc
        assert isinstance(self.start, tuple) and isinstance(self.before, tuple)
        assert len(self.start) == 2 and len(self.before) == 2
        assert self.start[0] <= self.before[0] and self.start[1] <= self.before[1]
        assert self.size() > 0 or (self.start == (0, 0) and self.before == (0, 0))

    def to_zoom(self, zoom):
        diff = zoom - self.zoom
        mult = pow(2, diff) if diff > 0 else 1 / pow(2, -diff)
        return TestCase(
            self.id, self.desc,
            (int(self.start[0] * mult), int(self.start[1] * mult)),
            (int(ceil(self.before[0] * mult)), int(ceil(self.before[1] * mult))),
            zoom=zoom)

    def size(self) -> int:
        return (self.before[0] - self.start[0]) * (self.before[1] - self.start[1])

    def fmt_table(self) -> str:
        pos = ''
        if self.size() > 0:
            pos = f" [{self.start[0]}/{self.start[1]}]" \
                  f"x[{self.before[0] - 1}/{self.before[1] - 1}]"
        res = f"* {self.id:10} {self.desc} ({self.size():,} tiles at z{self.zoom}{pos})"
        return res

    def format(self) -> str:
        return f"{self.id} - {self.desc} at zoom {self.zoom} ({self.size():,} tiles)"


# All test cases are defined on z14 by default. Second x,y pair is exclusive.
TEST_CASES: Dict[str, TestCase] = {v.id: v for v in [
    TestCase(
        'null',
        'Empty set, useful for query validation.', (0, 0), (0, 0)),
    TestCase(
        'us-across',
        'A line from Pacific ocean across US via New York and some Atlantic ocean',
        (2490, 6158), (4851, 6159)),
]}


async def async_main(tileset: str, test: List[str], layers: List[str], zooms: List[int],
                     dbname: str, pghost, pgport: str, user: str, password: str,
                     buckets: int, verbose: bool, summary=False):
    for tc in test:
        if tc not in TEST_CASES:
            cases = '\n'.join(map(TestCase.fmt_table, TEST_CASES.values()))
            raise DocoptExit(f"Test '{tc}' is not defined. "
                             f"Available tests are:\n{cases}\n")

    mvt = MvtGenerator(tileset, layer_ids=layers)

    prefix = 'CAST($1 as int) as z, xval.x as x, yval.y as y, ' if not summary else 'sum'
    query = f"""\
SELECT {prefix}(COALESCE(LENGTH((
{mvt.generate_query('TileBBox($1, xval.x, yval.y)', '$1')}
)), 0)) AS len FROM
generate_series(CAST($2 as int), CAST($3 as int)) AS xval(x),
generate_series(CAST($4 as int), CAST($5 as int)) AS yval(y);
"""

    if verbose:
        print(f'Using SQL query:\n\n-------\n\n{query}\n\n-------\n\n')

    results = []

    print(f'Connecting to PostgreSQL at {pghost}:{pgport}, db={dbname}, user={user}...')
    async with asyncpg.create_pool(
        database=dbname, host=pghost, port=pgport, user=user, password=password,
        min_size=1, max_size=1,
    ) as pool:
        async with pool.acquire() as conn:
            await show_settings(conn)
            for tc in test:
                for z in zooms:
                    case = TEST_CASES[tc].to_zoom(z)
                    await run_test(conn, query, case, buckets)
                    results.append(case)

    total_duration = round_td(reduce(lambda a, b: a + b, (v.duration for v in results)))
    total_size = reduce(lambda a, b: a + b, (v.size() for v in results))
    summary = f"Generated {total_size} tiles in {total_duration}, " \
              f"{total_size / total_duration.total_seconds():,.1f} tiles/s"
    print(f"\n\n================ SUMMARY ================")
    if len(results) > 1:
        zooms = list({v.zoom for v in results})
        zooms.sort()
        durations = defaultdict(timedelta)
        tile_counts = defaultdict(float)
        for res in results:
            durations[res.zoom] += res.duration
            tile_counts[res.zoom] += res.size()
        data = []
        for z in zooms:
            info = f"tiles/s at z{z}, {tile_counts[z]} total tiles in " \
                   f"{round_td(durations[z])}"
            data.append((info, tile_counts[z] / durations[z].total_seconds()))

        graph = Pyasciigraph(line_length=shutil.get_terminal_size((100, 20)).columns)
        for line in graph.graph(f"Per-zoom summary statistics:", data):
            print(line)
        print()

    print(summary)


async def show_settings(conn: Connection):
    print("Connection settings:")
    for setting in [
        'version()',
        'postgis_full_version()',
        'shared_buffers',
        'work_mem',
        'maintenance_work_mem',
        'max_connections',
        'max_worker_processes',
        'max_parallel_workers',
        'max_parallel_workers_per_gather',
    ]:
        q = f"{'SELECT' if '(' in setting else 'SHOW'} {setting};"
        try:
            res = await conn.fetchval(q)
        except (UndefinedFunctionError, UndefinedObjectError) as ex:
            res = ex.message
        print(f"* {setting:32} = {res}")


async def run_test(conn: Connection, query: str, test: TestCase, buckets: int):
    results = []

    print(f"\nRunning {test.format()}...")
    start = datetime.utcnow()
    for row in await conn.fetch(
        query,
        test.zoom,
        test.start[0], test.before[0] - 1,
        test.start[1], test.before[1] - 1,
    ):
        results.append(((row['z'], row['x'], row['y']), row['len']))
    test.duration = datetime.utcnow() - start

    tile_count = len(results)
    if tile_count != test.size():
        print(f"WARNING: Requested {test.size():,} tiles != returned {tile_count:,}")

    results.sort(key=lambda v: v[1])
    buckets = min(tile_count, buckets)
    sums = [0.0] * buckets
    first = [buckets + 1] * buckets
    last = [buckets + 1] * buckets
    last_ind = -1
    for ind, val in enumerate(results):
        i = int(ind / ceil(tile_count / buckets))
        sums[i] += val[1]
        last[i] = ind
        if last_ind != i:
            first[i] = ind
            last_ind = i

    data = []
    for i in range(buckets):
        frm = results[first[i]]
        utl = results[last[i]]
        info = f"{frm[1]:,} ({'/'.join(map(str, frm[0]))}) â€¥ " \
               f"{utl[1]:,} ({'/'.join(map(str, utl[0]))})"
        data.append((info, (round(sums[i] / (last[i] - first[i] + 1), 1))))

    if not data:
        print(f"Query returned no data after {test.duration}")
        return

    graph = Pyasciigraph(human_readable='cs',
                         line_length=shutil.get_terminal_size((100, 20)).columns)
    header = f"Tile size distribution for {tile_count:,} generated tiles " \
             f"({tile_count / buckets:.0f} per line) generated in " \
             f"{round_td(test.duration)} " \
             f"({tile_count / test.duration.total_seconds():,.1f} tiles/s)"
    for line in graph.graph(header, data):
        print(line)


if __name__ == '__main__':
    main(docopt(__doc__, version=openmaptiles.__version__))
